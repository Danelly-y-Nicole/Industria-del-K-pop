{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danelly-y-Nicole/Industria-del-K-pop/blob/main/K_pop_Modulo_de_Funciones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modulos de las funciones"
      ],
      "metadata": {
        "id": "KyExnylACXtg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wo4bp-_BUFRE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    return data\n",
        "\n",
        "def check_missing_ratio(data):\n",
        "    data_na = (data.isnull().sum() / len(data)) * 100\n",
        "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
        "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
        "    return missing_data\n",
        "\n",
        "def handle_duplicates(data):\n",
        "    duplicate_rows_data = data[data.duplicated()]\n",
        "    return duplicate_rows_data\n",
        "\n",
        "def preprocess_dates(data):\n",
        "    data['Debut'] = data['Debut'].replace('0/01/1900', pd.NA)\n",
        "    data['Date of Birth'] = pd.to_datetime(data['Date of Birth'], format='%d/%m/%Y')\n",
        "    data['Debut'] = pd.to_datetime(data['Debut'], format='%d/%m/%Y')\n",
        "\n",
        "    data['age'] = (datetime.now() - data['Date of Birth']).astype('<m8[Y]')\n",
        "    data['Debut Age'] = (data['Debut'] - data['Date of Birth']).astype('<m8[Y]')\n",
        "\n",
        "    data['year'], data['month'], data['day'] = data['Date of Birth'].apply(lambda x:x.year), data['Date of Birth'].apply(lambda x:x.month), data['Date of Birth'].apply(lambda x:x.day)\n",
        "\n",
        "    return data\n",
        "\n",
        "def map_gender_to_numeric(data):\n",
        "    gender_mapping = {'M': 1, 'F': 0}\n",
        "    data['Gender_numeric'] = data['Gender'].map(gender_mapping)\n",
        "    return data\n",
        "\n",
        "def save_preprocessed_data(data, output_file):\n",
        "    data.to_csv(output_file, index=False)\n",
        "\n",
        "# Load data\n",
        "file_path = 'kpopidolsv3.csv'\n",
        "data = extract_data(file_path)\n",
        "\n",
        "# Data preprocessing\n",
        "missing_data = check_missing_ratio(data)\n",
        "duplicate_rows_data = handle_duplicates(data)\n",
        "data_preprocessed = preprocess_dates(data)\n",
        "\n",
        "# Map Gender values to numeric values\n",
        "data_preprocessed = map_gender_to_numeric(data_preprocessed)\n",
        "\n",
        "# Save preprocessed data\n",
        "output_file = 'kpopidols_preprocessed.csv'\n",
        "save_preprocessed_data(data_preprocessed, output_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificando si se creo el archivo"
      ],
      "metadata": {
        "id": "0-oR9KY1U6T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta y nombre de archivo del CSV preprocesado\n",
        "output_file = 'kpopidols_preprocessed.csv'\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "if os.path.exists(output_file):\n",
        "    print(f\"El archivo '{output_file}' se creó correctamente.\")\n",
        "else:\n",
        "    print(f\"El archivo '{output_file}' no se creó o no se encuentra en la ubicación especificada.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsUxsexDU3AV",
        "outputId": "1b88215f-a97b-47b3-a44c-503dea548cbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo 'kpopidols_preprocessed.csv' se creó correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('kpopidols_preprocessed.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "id": "a4zdDNORbrPd",
        "outputId": "3518eea2-3216-44ac-8df7-c90a2c5ef9b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1778 entries, 0 to 1777\n",
            "Data columns (total 22 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Stage Name      1778 non-null   object \n",
            " 1   Full Name       1769 non-null   object \n",
            " 2   Korean Name     1768 non-null   object \n",
            " 3   K Stage Name    1777 non-null   object \n",
            " 4   Date of Birth   1776 non-null   object \n",
            " 5   Group           1632 non-null   object \n",
            " 6   Debut           1625 non-null   object \n",
            " 7   Company         1632 non-null   object \n",
            " 8   Country         1778 non-null   object \n",
            " 9   Second Country  62 non-null     object \n",
            " 10  Height          836 non-null    float64\n",
            " 11  Weight          566 non-null    float64\n",
            " 12  Birthplace      834 non-null    object \n",
            " 13  Other Group     140 non-null    object \n",
            " 14  Former Group    264 non-null    object \n",
            " 15  Gender          1778 non-null   object \n",
            " 16  age             1776 non-null   float64\n",
            " 17  Debut Age       1623 non-null   float64\n",
            " 18  year            1776 non-null   float64\n",
            " 19  month           1776 non-null   float64\n",
            " 20  day             1776 non-null   float64\n",
            " 21  Gender_numeric  1778 non-null   int64  \n",
            "dtypes: float64(7), int64(1), object(14)\n",
            "memory usage: 305.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proceso de ML"
      ],
      "metadata": {
        "id": "ccDzetrsXQpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clasificación de Género de los Idols"
      ],
      "metadata": {
        "id": "PFayV-URg32F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Carga los datos\n",
        "data = pd.read_csv('kpopidols_preprocessed.csv')\n",
        "\n",
        "def prepare_data(data):\n",
        "    selected_columns = ['Height', 'Weight', 'age', 'Debut Age', 'year', 'month', 'day', 'Gender_numeric']\n",
        "    data_selected = data[selected_columns]\n",
        "    return data_selected\n",
        "\n",
        "def impute_missing_values(data):\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    data_imputed = imputer.fit_transform(data)\n",
        "    return data_imputed\n",
        "\n",
        "def train_logistic_regression(X_train, y_train):\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Prepara los datos\n",
        "prepared_data = prepare_data(data)\n",
        "\n",
        "# Manejo de valores nulos (imputación)\n",
        "imputed_data = impute_missing_values(prepared_data)\n",
        "\n",
        "# Divide los datos en características (X) y etiquetas (y)\n",
        "X = imputed_data[:, :-1]\n",
        "y = imputed_data[:, -1]\n",
        "\n",
        "# Divide los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrena el modelo de regresión logística\n",
        "classification_model = train_logistic_regression(X_train, y_train)\n",
        "\n",
        "# Evalúa el modelo\n",
        "accuracy = evaluate_model(classification_model, X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "ENyk_VUvfwHP",
        "outputId": "6a270390-9adb-4eac-b120-bbb356688040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7162921348314607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción de la Estatura de los Idols"
      ],
      "metadata": {
        "id": "ecmagzE2hyVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('kpopidols_preprocessed.csv')\n",
        "\n",
        "def preprocess_data(data):\n",
        "    # Elimina columnas no relevantes\n",
        "    data = data.drop(['Stage Name', 'Full Name', 'Korean Name', 'K Stage Name', 'Gender'], axis=1)\n",
        "\n",
        "    # Codificación de variables categóricas\n",
        "    categorical_columns = ['Group', 'Company', 'Country', 'Second Country', 'Birthplace', 'Other Group', 'Former Group']\n",
        "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "    encoded_columns = pd.DataFrame(encoder.fit_transform(data[categorical_columns]))\n",
        "    encoded_columns.columns = encoder.get_feature_names_out(categorical_columns)\n",
        "    data = pd.concat([data.drop(categorical_columns, axis=1), encoded_columns], axis=1)\n",
        "\n",
        "    # Transformación de fechas\n",
        "    data['Date of Birth'] = pd.to_datetime(data['Date of Birth'])\n",
        "    data['Debut'] = pd.to_datetime(data['Debut'])\n",
        "    reference_date = pd.to_datetime('2023-01-01')\n",
        "    data['Age_at_Debut'] = (data['Debut'] - data['Date of Birth']).dt.days\n",
        "    data = data.drop(['Date of Birth', 'Debut'], axis=1)\n",
        "\n",
        "    # Elimina filas con valores nulos\n",
        "    data = data.dropna()\n",
        "\n",
        "    return data\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "    # Entrena el modelo de RandomForestRegressor\n",
        "    regression_model = RandomForestRegressor(random_state=42)\n",
        "    regression_model.fit(X_train, y_train)\n",
        "    return regression_model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Evalúa el modelo\n",
        "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
        "    return mse\n",
        "\n",
        "\n",
        "data = preprocess_data(data)\n",
        "\n",
        "# División de características (X) y etiquetas (y)\n",
        "X = data.drop('Height', axis=1)\n",
        "y = data['Height']\n",
        "\n",
        "# División de datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = train_model(X_train, y_train)\n",
        "\n",
        "mse = evaluate_model(model, X_test, y_test)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3bFWxBQpcHR",
        "outputId": "ab262071-9bd1-467b-fa81-4531f45920a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 11.774937864077655\n"
          ]
        }
      ]
    }
  ]
}
